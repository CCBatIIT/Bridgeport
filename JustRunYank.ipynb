{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf31cce4-975a-4c54-91ae-fa0fbd17678b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import textwrap\n",
    "import MDAnalysis as mda\n",
    "import openmmtools as mmtools\n",
    "import yank.utils\n",
    "import numpy as np\n",
    "import yaml\n",
    "import yank\n",
    "from yank.experiment import YankLoader, YankDumper\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, glob, shutil\n",
    "from mdtraj.formats.dcd import DCDTrajectoryFile\n",
    "import mdtraj as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d06182f-9def-4c17-8ae6-24eb318f66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_restrained_residues(structure_file, n_closest, ligand_string):\n",
    "    #Find CAs and UQ4\n",
    "    u = mda.Universe(structure_file)\n",
    "    protein_CAs = u.select_atoms('protein and name CA')\n",
    "    uq = u.select_atoms(ligand_string)\n",
    "    uq_com = uq.center_of_mass()\n",
    "    #Build a list of resnames resids and distances (sort by distance)\n",
    "    residues = []\n",
    "    for atom in protein_CAs:\n",
    "        dist = np.sqrt(np.sum((atom.position - uq_com)**2))\n",
    "        residues.append([atom.resname, atom.resindex, dist])\n",
    "    residues = sorted(residues, key = lambda x: x[2])\n",
    "    #Craft the restraint string\n",
    "    restraint_string = ''\n",
    "    for res in residues[:n_closest]:\n",
    "        restraint_string += f'(resname {res[0]} and resid {res[1]}) or '\n",
    "    restraint_string = restraint_string[:-4]\n",
    "    return restraint_string    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef60a110-414b-4230-b212-bdaec0c25887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a yaml file\n",
    "def write_the_yaml(complex_fns, solvent_fns, ligand_string, out_dir, restraint_string):\n",
    "    yaml_contents = f\"\"\"---\n",
    "experiments:\n",
    "  protocol: absolute-binding\n",
    "  restraint:\n",
    "    type: FlatBottom\n",
    "    restrained_receptor_atoms: {restraint_string}\n",
    "    restrained_ligand_atoms: all\n",
    "    spring_constant: 10.0*kilocalories_per_mole/(angstrom**2)\n",
    "    well_radius: 8.0*angstroms\n",
    "  system: rec-lig\n",
    "options:\n",
    "  default_nsteps_per_iteration: 500\n",
    "  default_number_of_iterations: 50\n",
    "  default_timestep: 1.0*femtosecond\n",
    "  minimize: no\n",
    "  number_of_equilibration_iterations: 0\n",
    "  output_dir: {out_dir}\n",
    "  platform: fastest\n",
    "  pressure: 1.0*atmosphere\n",
    "  resume_simulation: yes\n",
    "  temperature: 300*kelvin\n",
    "  verbose: yes\n",
    "protocols:\n",
    "  absolute-binding:\n",
    "    complex:\n",
    "      alchemical_path: auto\n",
    "      trailblazer_options:\n",
    "        bidirectional_redistribution: yes\n",
    "        constrain_receptor: false\n",
    "        distance_tolerance: 0.05\n",
    "        n_equilibration_iterations: 0\n",
    "        n_samples_per_state: 100\n",
    "        reversed_direction: yes\n",
    "        thermodynamic_distance: 1\n",
    "    solvent:\n",
    "      alchemical_path: auto\n",
    "      trailblazer_options:\n",
    "        bidirectional_redistribution: yes\n",
    "        constrain_receptor: false\n",
    "        distance_tolerance: 0.05\n",
    "        n_equilibration_iterations: 0\n",
    "        n_samples_per_state: 100\n",
    "        reversed_direction: yes\n",
    "        thermodynamic_distance: 1\n",
    "solvents:\n",
    "  PME:\n",
    "    nonbonded_cutoff: 8.0*angstroms\n",
    "    nonbonded_method: PME\n",
    "systems:\n",
    "  rec-lig:\n",
    "    ligand_dsl: {ligand_string}\n",
    "    phase1_path:\n",
    "    - {complex_fns[0]}\n",
    "    - {complex_fns[1]}\n",
    "    phase2_path:\n",
    "    - {solvent_fns[0]}\n",
    "    - {solvent_fns[1]}\n",
    "    solvent: PME\"\"\"\n",
    "    return yaml_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0179ef77-a92c-4c9c-b7de-8d426955037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YankWrapper():\n",
    "    \"\"\"Wrapper for YANK that\n",
    "    * TODO: initializes configurations from a set of predefined structures\n",
    "    * insert thermodynamic states as necessary\n",
    "    * TODO: performs a pose prediction by clustering of ligand positions\n",
    "    \"\"\"\n",
    "    def __init__(self, yaml_init_fn):\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        yaml_fn : string\n",
    "            The yaml file that is used to initialize YANK with an automated protocol\n",
    "        \n",
    "        \"\"\"\n",
    "        # Load the initial yaml. Based on this, determine yank_store directory and current yaml\n",
    "        self.yaml_init_fn = os.path.abspath(yaml_init_fn)\n",
    "        with open(self.yaml_init_fn, 'r') as f:\n",
    "            self.yaml_init = yaml.load(f, Loader=YankLoader)\n",
    "        try:\n",
    "            self.yank_store = f'/ocean/projects/bio230003p/dcooper/yank/{name}/{name}_{run}'\n",
    "        except:\n",
    "            self.yank_store = os.path.join(os.path.dirname(self.yaml_init_fn), self.yaml_init['options']['output_dir'])\n",
    "        self.yaml_current_fn = os.path.join(self.yank_store,'experiments','experiments.yaml')\n",
    "        assert hasattr(self, 'yaml_init_fn') and hasattr(self, 'yaml_init') \n",
    "        \n",
    "        #Try to run yank, if it has been run, then this will simply pass\n",
    "        yaml_builder = yank.experiment.ExperimentBuilder(script=self.yaml_init)\n",
    "        yaml_builder.run_experiments()\n",
    "                \n",
    "        #YANK Throws a strange error, it cannot be restarted with the file names as elements of the dictionary\n",
    "        # see such lines created by yank that look like (below) and should be deleted from yaml_current prior\n",
    "        # /ocean/projects/bio230003p/dcooper/PosePred/data/fentanyl/fentanyl_1.inpcrd: ../../fentanyl_1.inpcrd\n",
    "        # a simple fix may be to delete any lines containing '../..' for now\n",
    "        with open(self.yaml_current_fn, 'r') as f: #Read and filter contents\n",
    "            lines = [line for line in f.readlines() if \"../..\" not in line]\n",
    "        with open(self.yaml_current_fn, 'w') as f: #write\n",
    "            f.writelines(lines)\n",
    "        with open(self.yaml_current_fn, 'r') as f:\n",
    "            self.yaml_current = yaml.load(f, Loader=YankLoader)\n",
    "        \n",
    "        assert hasattr(self, 'yaml_current_fn') and hasattr(self, 'yaml_current')\n",
    "        self.yaml_current['options']['output_dir'] = self.yank_store\n",
    "\n",
    "        ##write progress.log file \n",
    "        if os.path.exists(prog_path):\n",
    "            pass \n",
    "        else:\n",
    "            with open(prog_path, 'a+') as f:\n",
    "                f.write(f'LOG FILE FOR {name} {run} YANK POSE PREDICTION\\nOne Simulation Ran\\n')\n",
    "                f.close()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def n_more_iters(self, n):\n",
    "        self.yaml_init['options']['default_number_of_iterations'] += n\n",
    "        with open(self.yaml_current_fn, 'w') as f:\n",
    "            f.write(yaml.dump(self.yaml_current, Dumper=YankDumper))\n",
    "\n",
    "    def acceptance_rate(self, phase='complex'):\n",
    "        \"\"\" Evaluate the replica exchange acceptance rate between neighbors\n",
    "        \"\"\"\n",
    "        from openmmtools.multistate.multistatereporter import MultiStateReporter\n",
    "        nc_fn = os.path.join(self.yank_store,'experiments',f'{phase}.nc')\n",
    "        msr = MultiStateReporter(nc_fn,'r')\n",
    "        (n_accepted_matrix, n_proposed_matrix) = msr.read_mixing_statistics()\n",
    "        msr.close()\n",
    "        fifth = int(n_accepted_matrix.shape[0]/5.)\n",
    "        acc_rate_matrix = np.sum(n_accepted_matrix[-fifth:,:,:],0) / \\\n",
    "                          np.sum(n_proposed_matrix[-fifth:,:,:],0)\n",
    "        acc_rate = np.array([acc_rate_matrix[i][i+1] \\\n",
    "                             for i in range(acc_rate_matrix.shape[0] - 1)])\n",
    "        return acc_rate            \n",
    "            \n",
    "    def run_yank(self):\n",
    "        yaml_builder = yank.experiment.ExperimentBuilder(script=self.yaml_current)\n",
    "        yaml_builder.run_experiments()\n",
    "        \n",
    "    def get_nc_state(self, state, dcd_save_fn, phase='complex', yank_nc_fn=True):\n",
    "        if yank_nc_fn == True:\n",
    "            yank_nc_fn = f'{self.yank_store}/experiments/{phase}.nc'\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        ncdf = nc.Dataset(yank_nc_fn, 'r+')\n",
    "        \n",
    "        positions = np.zeros((ncdf.dimensions['iteration'].size, \\\n",
    "                              ncdf.dimensions['atom'].size, \\\n",
    "                              ncdf.dimensions['spatial'].size))\n",
    "        \n",
    "        for i in range(ncdf.dimensions['iteration'].size):\n",
    "            state_ind = ncdf.variables['states'][i, :].index(state)\n",
    "            positions[i, :, :] = ncdf.variables['positions'] #nm positions\n",
    "        \n",
    "        with DCDTrajectoryFile(dcd_save_fn, 'w') as f:\n",
    "            f.write(positions)\n",
    "        \n",
    "        \n",
    "    def _insert_states(self, threshold=0.45, phase='complex'):\n",
    "        \"\"\" Inserts a state whereever there is a bottleneck\n",
    "        \"\"\"\n",
    "        assert phase == 'complex' or phase == 'solvent'\n",
    "        \n",
    "        acc_rate = self.acceptance_rate(phase)\n",
    "        inds = [ind for ind in range(acc_rate.shape[0]) if acc_rate[ind] < threshold]\n",
    "        print(inds, acc_rate)\n",
    "        if len(inds)==0:\n",
    "            return False\n",
    "        \n",
    "        # Insert states into protocol\n",
    "        n_states_o = acc_rate.shape[0]+1\n",
    "        n_states_n = n_states_o + len(inds)\n",
    "        print(f'Starting with {n_states_o} states, inserting {len(inds)} states')\n",
    "        \n",
    "        # Expand the protocol\n",
    "        alchemical_paths = self.yaml_current['protocols']['absolute-binding'][phase]['alchemical_path']\n",
    "        for key in alchemical_paths.keys():\n",
    "            for ind in inds[::-1]:\n",
    "                mean_parameter = (alchemical_paths[key][ind] + alchemical_paths[key][ind+1])/2\n",
    "                alchemical_paths[key] = alchemical_paths[key][:ind+1] + [mean_parameter] + \\\n",
    "                                        alchemical_paths[key][ind+1:]\n",
    "        print(len(alchemical_paths[key]), n_states_n)\n",
    "        # assert len(alchemical_paths[key])==n_states_n\n",
    "        \n",
    "        # Write new protocol to the current YAML\n",
    "        import shutil\n",
    "        shutil.copy(self.yaml_current_fn,\n",
    "                    self.yaml_current_fn[:self.yaml_current_fn.rfind('.')] + f'_{n_states_o}.yaml')\n",
    "        with open(self.yaml_current_fn, 'w') as f:\n",
    "            f.write(yaml.dump(self.yaml_current, Dumper=YankDumper))\n",
    "        \n",
    "        # Opens the YANK netcdf file and coordinates.dcd file\n",
    "        yank_nc_fn = f'{self.yank_store}/experiments/{phase}.nc'\n",
    "        ncdf = nc.Dataset(yank_nc_fn, 'r+')\n",
    "        if phase == 'complex':\n",
    "            phase_num = 'phase1_path'\n",
    "        elif phase == 'solvent':\n",
    "            phase_num = 'phase2_path'\n",
    "        coords_traj = md.load_dcd(f'{self.yank_store}/experiments/trailblaze/{phase}/coordinates.dcd',\\\n",
    "                                 top = self.yaml_current['systems']['rec-lig'][phase_num][0])\n",
    "        with open(f'{self.yank_store}/experiments/trailblaze/{phase}/states_map.json', 'r') as f:\n",
    "            states_map_inds = eval(f.read())\n",
    "        \n",
    "        # Extract a positions from coords.dcd and box vectors from the YANK netcdf output\n",
    "        \n",
    "        # EXTRACTING FROM THE NETCDF DOES NOT GET WATERS which are required in coords.dcd\n",
    "        positions = np.zeros((ncdf.dimensions['replica'].size, \\\n",
    "                          coords_traj.xyz.shape[1], \\\n",
    "                          ncdf.dimensions['spatial'].size))\n",
    "        cell_lengths = np.zeros((ncdf.dimensions['replica'].size, \\\n",
    "                                 ncdf.dimensions['spatial'].size))\n",
    "        for r in range(ncdf.dimensions['replica'].size):\n",
    "            s = ncdf.variables['states'][-1, r] # State index of replica r in the last iteration\n",
    "            #retrieve sth index of states_map from coordinates.dcd\n",
    "            positions[s, :, :] = coords_traj.xyz[states_map_inds[s]]*10\n",
    "            cell_lengths[s, :] = np.diag(ncdf.variables['box_vectors'][-1, r, :, :])*10\n",
    "\n",
    "        inds_with_duplicates = sorted([ind for ind in range(ncdf.dimensions['replica'].size)] + inds)\n",
    "        positions = positions[inds_with_duplicates, :, :]\n",
    "        cell_lengths = cell_lengths[inds_with_duplicates, :]\n",
    "\n",
    "        # Write new protocol to the trailblaze YAML\n",
    "        yaml_fn = f'{self.yank_store}/experiments/trailblaze/{phase}/protocol.yaml'\n",
    "        yaml_o_fn = f'{self.yank_store}/experiments/trailblaze/{phase}/protocol_{n_states_o}.yaml'\n",
    "        shutil.copy(yaml_fn, yaml_o_fn)\n",
    "        with open(yaml_fn, 'w') as f:\n",
    "            f.write(yaml.dump(alchemical_paths, Dumper=YankDumper))\n",
    "        \n",
    "        # Write a new trailblaze states_map\n",
    "        map_fn = f'{self.yank_store}/experiments/trailblaze/{phase}/states_map.json'\n",
    "        map_o_fn = f'{self.yank_store}/experiments/trailblaze/{phase}/states_map_{n_states_o}.json'\n",
    "        shutil.copy(map_fn, map_o_fn)\n",
    "        with open(map_fn, 'w') as f:\n",
    "            f.write(repr([ind for ind in range(n_states_n)]))\n",
    "\n",
    "        # Generates a DCD file with duplicated coordinates\n",
    "        DCD_fn = f'{self.yank_store}/experiments/trailblaze/{phase}/coordinates.dcd'\n",
    "        DCD_o_fn = f'{self.yank_store}/experiments/trailblaze/{phase}/coordinates_{n_states_o}.dcd'\n",
    "        shutil.copy(DCD_fn, DCD_o_fn)\n",
    "        with DCDTrajectoryFile(DCD_fn, 'w') as f:\n",
    "            f.write(positions, cell_lengths=cell_lengths, cell_angles=[[90., 90., 90.]]*len(inds_with_duplicates))\n",
    "        \n",
    "        # With this, previous netcdf can be renamed or deleted in order to allow\n",
    "        #  a new one to be initialized from the new information in the setup directory\n",
    "\n",
    "        #update progress.log \n",
    "        with open(prog_path, 'a') as f:\n",
    "            f.write(f'STATE INSERTION:\\n   {n_states_o} evaluated with accpetance rate: {acc_rate}\\n   New number of states after insertion: {n_states_n}\\n')\n",
    "        return True\n",
    "\n",
    "    def graph_states(self, phase='complex'):\n",
    "        \"\"\" TODO: add _retreieve_states again\n",
    "        \"\"\"\n",
    "        elecs, sters, rests, overlaps = self._retrieve_states(phase=phase)\n",
    "        xs = np.arange(len(elecs))\n",
    "        plt.clf()\n",
    "        for yset in (elecs, sters, rests):\n",
    "            plt.scatter(xs, yset)\n",
    "        plt.scatter(xs[:-1]+0.5, overlaps)\n",
    "        plt.legend(('Elec','Ster','Rest','OvrLp'),loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "    def _pose_insertion(self, list_of_pdb_fns, phase='complex'): #\n",
    "        \"\"\" Replace the frames present in $YANK_STORE/experiments/trailblaze/$PHASE/coordinates.dcd\n",
    "            With poses from a list of pdbs\n",
    "            \n",
    "            No matter the number of replicates, we would like to replace all with these poses\"\"\"\n",
    "                \n",
    "        assert phase == 'complex' or phase == 'solvent'\n",
    "        \n",
    "        yank_nc_fn = f'{self.yank_store}/experiments/{phase}.nc'\n",
    "        ncdf = nc.Dataset(yank_nc_fn, 'r')\n",
    "        if phase == 'complex':\n",
    "            phase_num = 'phase1_path'\n",
    "        elif phase == 'solvent':\n",
    "            phase_num = 'phase2_path'\n",
    "        coords_traj = md.load_dcd(f'{self.yank_store}/experiments/trailblaze/{phase}/coordinates.dcd',\\\n",
    "                                 top = self.yaml_current['systems']['rec-lig'][phase_num][0])\n",
    "        \n",
    "        # Define positions array with appropriate dimensions\n",
    "        poses_positions = np.zeros((ncdf.dimensions['replica'].size, \\\n",
    "                          coords_traj.xyz.shape[1], \\\n",
    "                          ncdf.dimensions['spatial'].size))\n",
    "        # Cell Lengths\n",
    "        cell_lengths = np.zeros((ncdf.dimensions['replica'].size, \\\n",
    "                                 ncdf.dimensions['spatial'].size))\n",
    "        #Iterate over poses provided to build new coordinate array\n",
    "        #Iterate from i until ncdf.dimensions['replica'].size, but if i>(len of pdb_list), wrap around\n",
    "        for i in range(ncdf.dimensions['replica'].size): # replace every replica with one of our structures\n",
    "            #Coordinate\n",
    "            pdb_list_ind = i % len(list_of_pdb_fns)\n",
    "            traj = md.load_pdb(list_of_pdb_fns[pdb_list_ind])\n",
    "            #not_h20_atom_inds = traj.topology.select('not water')\n",
    "            atom_inds = traj.topology.select('all')\n",
    "            poses_positions[i, :, :] = traj.xyz[:, atom_inds, :]*10 #mdtraj in nm ##check after pose insertion, units could be issue\n",
    "            #Cell\n",
    "            s = ncdf.variables['states'][-1, i] # State index of replica r in the last iteration\n",
    "            cell_lengths[s, :] = np.diag(ncdf.variables['box_vectors'][-1, i, :, :])*10.\n",
    "        \n",
    "        cell_angles = [[90., 90., 90.]]*ncdf.dimensions['replica'].size\n",
    "        \n",
    "        #Save this new array to coordinates.dcd\n",
    "        DCD_fn   = f'{self.yank_store}/experiments/trailblaze/{phase}/coordinates.dcd'\n",
    "        DCD_o_fn = f'{self.yank_store}/experiments/trailblaze/{phase}/coordinates_preinsert.dcd'\n",
    "        shutil.copy(DCD_fn, DCD_o_fn)\n",
    "\n",
    "        f = DCDTrajectoryFile(DCD_fn, 'w')\n",
    "        f.write(poses_positions, cell_lengths=cell_lengths, cell_angles=cell_angles)\n",
    "        f.close()\n",
    "        \n",
    "        #coordinates.dcd is no longer as large as it was before, so the indices in staes_map are not appropriate\n",
    "        # Write a new trailblaze states_map\n",
    "        map_fn = f'{self.yank_store}/experiments/trailblaze/{phase}/states_map.json'\n",
    "        map_o_fn = f'{self.yank_store}/experiments/trailblaze/{phase}/states_map_preinsert.json'\n",
    "        shutil.copy(map_fn, map_o_fn)\n",
    "        with open(map_fn, 'w') as f:\n",
    "            f.write(repr([ind for ind in range(ncdf.dimensions['replica'].size)]))\n",
    "\n",
    "        #update progress.log \n",
    "        with open(prog_path, 'a') as f:\n",
    "            f.write(f'POSES INSERTED\\n')\n",
    "        return True\n",
    "\n",
    "    \n",
    "    # Insert states\n",
    "    def state_evaluation(self):\n",
    "        ##START JOB METHOD\n",
    "        \n",
    "        acc_rate = experiment.acceptance_rate(phase='complex')\n",
    "        n_states_o = acc_rate.shape[0]+1\n",
    "        while self._insert_states():\n",
    "            print(\"states were inserted\")\n",
    "            #States were inserted, so the netcdf should be deleted\n",
    "            #yank_nc_fn = f'{self.yank_store}/experiments/{phase}.nc'\n",
    "            \n",
    "            #Reset NetCDFs\n",
    "            for fn in ['complex','solvent']:\n",
    "                if os.path.isfile(f'{self.yank_store}/experiments/{fn}.nc'):\n",
    "                    shutil.copy(f'{self.yank_store}/experiments/{fn}.nc',\\\n",
    "                                f'{self.yank_store}/experiments/{fn}_{n_states_o}.nc')\n",
    "                    os.remove(f'{self.yank_store}/experiments/{fn}.nc')\n",
    "                if os.path.isfile(f'{self.yank_store}/experiments/{fn}_checkpoint.nc'):\n",
    "                    shutil.copy(f'{self.yank_store}/experiments/{fn}_checkpoint.nc',\\\n",
    "                                f'{self.yank_store}/experiments/{fn}_checkpoint_{n_states_o}.nc')\n",
    "                    os.remove(f'{self.yank_store}/experiments/{fn}_checkpoint.nc')\n",
    "            \n",
    "            print(self.yaml_current)\n",
    "            with open(prog_path, 'a') as f:\n",
    "                f.write(f'CHECKING STATES\\n')\n",
    "            self.run_yank()\n",
    "\n",
    "        with open(prog_path, 'a') as f:\n",
    "            f.write(f'NUMBER OF STATES IS SUFFICIENT\\n')        \n",
    "        print(f'\\nNUMBER OF STATES IS SUFFICIENT\\n')\n",
    "\n",
    "    ##insert poses\n",
    "    def insert_poses_now(self, list_of_pdb_fns):\n",
    "        acc_rate = experiment.acceptance_rate(phase='complex')\n",
    "        n_states_o = acc_rate.shape[0]+1\n",
    "        if self._pose_insertion(list_of_pdb_fns):\n",
    "            print(\"poses were inserted\")\n",
    "            #Reset NetCDFs\n",
    "            for fn in ['complex','solvent']:\n",
    "                if os.path.isfile(f'{self.yank_store}/experiments/{fn}.nc'):\n",
    "                    shutil.copy(f'{self.yank_store}/experiments/{fn}.nc',\\\n",
    "                                f'{self.yank_store}/experiments/{fn}_{n_states_o}.nc')\n",
    "                    os.remove(f'{self.yank_store}/experiments/{fn}.nc')\n",
    "                if os.path.isfile(f'{self.yank_store}/experiments/{fn}_checkpoint.nc'):\n",
    "                    shutil.copy(f'{self.yank_store}/experiments/{fn}_checkpoint.nc',\\\n",
    "                                f'{self.yank_store}/experiments/{fn}_checkpoint_{n_states_o}.nc')\n",
    "                    os.remove(f'{self.yank_store}/experiments/{fn}_checkpoint.nc')\n",
    "\n",
    "            self.run_yank() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82959d8-705e-4519-97a4-2b05ea033228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complex_fns = ('NQR_UQ4/Protein_UQ4.gro','NQR_UQ4/Protein_UQ4.top')\n",
    "complex_fns = ('system.pdb', 'system.xml')\n",
    "solvent_fns = ('NQR_UQ4/UQ4_memb.gro','NQR_UQ4/UQ4_memb.top')\n",
    "ligand_resname = 'resname lig'\n",
    "yank_output_dir = 'UNK/yankrun'\n",
    "yaml_file_fn = 'UNK/yank_script.yaml'\n",
    "restraint_string = determine_restrained_residues('system.pdb', 4, ligand_resname)\n",
    "\n",
    "with open(yaml_file_fn, 'w') as f:\n",
    "    f.write(write_the_yaml(complex_fns, solvent_fns, ligand_resname, yank_output_dir, restraint_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3139db9-b3e0-4dc8-9347-1bd87b0a4906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 20:43:36,435: Setting CUDA platform to use precision model 'mixed'.\n",
      "2023-09-19 20:43:36,478: Correctly recognized phase1_pathfiles (['system.pdb', 'system.xml']) as openmm files\n",
      "2023-09-19 20:43:36,479: Correctly recognized phase2_pathfiles (['NQR_UQ4/UQ4_memb.gro', 'NQR_UQ4/UQ4_memb.top']) as gromacs files\n",
      "2023-09-19 20:43:36,496: You are specifying a string for receptor atoms, the final atoms will be chosen as the centroid of this set.after calling \"determine_missing_parameters()\" to process the string\n",
      "2023-09-19 20:43:36,497: You are specifying a string for ligand atoms, the final atoms will be chosen as the centroid of this set.after calling \"determine_missing_parameters()\" to process the string\n"
     ]
    }
   ],
   "source": [
    "with open(yaml_file_fn, 'r') as f:\n",
    "    my_yaml = yaml.load(f, Loader=YankLoader)\n",
    "yaml_builder = yank.experiment.ExperimentBuilder(script=my_yaml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be6a7333-f481-4e1e-b812-3183fb237306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 20:43:37,449: Single node: executing <function ExperimentBuilder._check_resume at 0x7f66b44141f0>\n",
      "2023-09-19 20:43:37,451: Running _setup_molecules serially.\n",
      "2023-09-19 20:43:37,451: Running get_system serially.\n",
      "2023-09-19 20:43:37,452: Running _generate_experiment_protocol serially.\n",
      "2023-09-19 20:43:37,453: DSL string for the ligand: \"resname lig\"\n",
      "2023-09-19 20:43:37,453: DSL string for the solvent: \"auto\"\n",
      "2023-09-19 20:43:37,454: Reading phase complex\n",
      "2023-09-19 20:43:37,454: xml: system.xml\n",
      "2023-09-19 20:43:37,455: pdb: system.pdb\n",
      "2023-09-19 20:43:39,600: Single node: executing <function find_alchemical_counterions at 0x7f66b62cb700>\n",
      "2023-09-19 20:43:39,602: ligand_atoms net charge: 0\n",
      "2023-09-19 20:43:39,604: You are specifying a string for receptor atoms, the final atoms will be chosen as the centroid of this set.after calling \"determine_missing_parameters()\" to process the string\n",
      "2023-09-19 20:43:39,605: You are specifying a string for ligand atoms, the final atoms will be chosen as the centroid of this set.after calling \"determine_missing_parameters()\" to process the string\n",
      "2023-09-19 20:43:39,606: WARNING - openmmtools.multistate.multistatesampler - Warning: The openmmtools.multistate API is experimental and may change in future releases\n",
      "2023-09-19 20:43:39,630: CUDA devices available: ('uuid, name, compute_mode', 'GPU-05d0a720-5726-11ee-85db-7ed199dad2da, GRID A100X-10C, Default')\n",
      "2023-09-19 20:43:39,632: Reading phase solvent\n",
      "2023-09-19 20:43:39,632: top: NQR_UQ4/UQ4_memb.top\n",
      "2023-09-19 20:43:39,632: gro: NQR_UQ4/UQ4_memb.gro\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2491: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.name is 'CA' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2495: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.element.symbol is 'C' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2491: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.name is 'CA' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2495: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.element.symbol is 'C' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2491: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.name is 'CA' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2495: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.element.symbol is 'C' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2491: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.name is 'CA' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2495: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.element.symbol is 'C' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2491: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.name is 'CA' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2495: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.element.symbol is 'C' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2491: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.name is 'CA' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2495: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.element.symbol is 'C' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2491: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.name is 'CA' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2495: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.element.symbol is 'C' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2491: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.name is 'CA' and atom.index in receptor_atoms_set]\n",
      "/home/exouser/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2495: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if atom.element.symbol is 'C' and atom.index in receptor_atoms_set]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported function type in [ pairs ] line:      1    11     2 0.833333    -0.125447    -0.033096  3.39966950842e-01  7.62882666667e-02\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43myaml_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:738\u001b[0m, in \u001b[0;36mExperimentBuilder.run_experiments\u001b[0;34m(self, write_status)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_resume()\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_experiments()\n\u001b[0;32m--> 738\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_experiments_protocols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# Find all the experiments to distribute among mpicomms.\u001b[39;00m\n\u001b[1;32m    741\u001b[0m all_experiments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_experiments())\n",
      "File \u001b[0;32m~/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2371\u001b[0m, in \u001b[0;36mExperimentBuilder._generate_experiments_protocols\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_yaml(experiment, script_filepath)\n\u001b[1;32m   2370\u001b[0m \u001b[38;5;66;03m# Parallelize generation of all protocols among nodes.\u001b[39;00m\n\u001b[0;32m-> 2371\u001b[0m \u001b[43mmpiplus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_experiment_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2372\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mdistributed_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiments_to_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2373\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msend_results_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msync_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openff/lib/python3.9/site-packages/mpiplus/mpiplus.py:523\u001b[0m, in \u001b[0;36mdistribute\u001b[0;34m(task, distributed_args, send_results_to, propagate_exceptions_to, sync_nodes, group_size, *other_args, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_mpicomm() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m serially.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(task\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n\u001b[0;32m--> 523\u001b[0m     all_results \u001b[38;5;241m=\u001b[39m [task(job_args, \u001b[38;5;241m*\u001b[39mother_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m job_args \u001b[38;5;129;01min\u001b[39;00m distributed_args]\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m send_results_to \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m all_results\n",
      "File \u001b[0;32m~/miniconda3/envs/openff/lib/python3.9/site-packages/mpiplus/mpiplus.py:523\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_mpicomm() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m serially.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(task\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n\u001b[0;32m--> 523\u001b[0m     all_results \u001b[38;5;241m=\u001b[39m [\u001b[43mtask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m job_args \u001b[38;5;129;01min\u001b[39;00m distributed_args]\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m send_results_to \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m all_results\n",
      "File \u001b[0;32m~/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:2416\u001b[0m, in \u001b[0;36mExperimentBuilder._generate_experiment_protocol\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m   2410\u001b[0m phases_to_generate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_automatic_protocol_phases(protocol)\n\u001b[1;32m   2412\u001b[0m \u001b[38;5;66;03m# We build the experiment normally so that we can run trailblaze\u001b[39;00m\n\u001b[1;32m   2413\u001b[0m \u001b[38;5;66;03m# on a thermodynamic state and MCMC move that are identical to the\u001b[39;00m\n\u001b[1;32m   2414\u001b[0m \u001b[38;5;66;03m# actual experiment. Use a dummy protocol for building since it\u001b[39;00m\n\u001b[1;32m   2415\u001b[0m \u001b[38;5;66;03m# hasn't been generated yet.\u001b[39;00m\n\u001b[0;32m-> 2416\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2417\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_dummy_protocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2419\u001b[0m \u001b[38;5;66;03m# Generate protocols for all the required phases.\u001b[39;00m\n\u001b[1;32m   2420\u001b[0m optimal_protocols \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mOrderedDict\u001b[38;5;241m.\u001b[39mfromkeys(phases_to_generate)\n",
      "File \u001b[0;32m~/miniconda3/envs/openff/lib/python3.9/site-packages/yank/experiment.py:3108\u001b[0m, in \u001b[0;36mExperimentBuilder._build_experiment\u001b[0;34m(self, experiment_path, experiment, use_dummy_protocol)\u001b[0m\n\u001b[1;32m   3106\u001b[0m     system_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_db\u001b[38;5;241m.\u001b[39msolvents[solvent_id], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexp_opts}\n\u001b[1;32m   3107\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading phase \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(phase_name))\n\u001b[0;32m-> 3108\u001b[0m system, topology, sampler_state \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_system_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositions_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgromacs_include_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgromacs_include_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3112\u001b[0m \u001b[38;5;66;03m# Identify system components. There is a ligand only in the complex phase.\u001b[39;00m\n\u001b[1;32m   3113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/openff/lib/python3.9/site-packages/yank/pipeline.py:489\u001b[0m, in \u001b[0;36mread_system_files\u001b[0;34m(positions_file_path, parameters_file_path, system_options, gromacs_include_dir)\u001b[0m\n\u001b[1;32m    486\u001b[0m         positions_file\u001b[38;5;241m.\u001b[39m_periodicBoxVectors[frame] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    488\u001b[0m box_vectors \u001b[38;5;241m=\u001b[39m positions_file\u001b[38;5;241m.\u001b[39mgetPeriodicBoxVectors()\n\u001b[0;32m--> 489\u001b[0m parameters_file \u001b[38;5;241m=\u001b[39m \u001b[43mopenmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGromacsTopFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mperiodicBoxVectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbox_vectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mincludeDir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgromacs_include_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m create_system_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(inspect\u001b[38;5;241m.\u001b[39mgetargspec(openmm\u001b[38;5;241m.\u001b[39mapp\u001b[38;5;241m.\u001b[39mGromacsTopFile\u001b[38;5;241m.\u001b[39mcreateSystem)\u001b[38;5;241m.\u001b[39margs)\n\u001b[1;32m    494\u001b[0m system \u001b[38;5;241m=\u001b[39m create_system(parameters_file, box_vectors, create_system_args, system_options)\n",
      "File \u001b[0;32m~/miniconda3/envs/openff/lib/python3.9/site-packages/openmm/app/gromacstopfile.py:537\u001b[0m, in \u001b[0;36mGromacsTopFile.__init__\u001b[0;34m(self, file, periodicBoxVectors, unitCellDimensions, includeDir, defines)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmapTypes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nonbondTypes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 537\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_processFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# Create the Topology from it.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m top \u001b[38;5;241m=\u001b[39m Topology()\n",
      "File \u001b[0;32m~/miniconda3/envs/openff/lib/python3.9/site-packages/openmm/app/gromacstopfile.py:131\u001b[0m, in \u001b[0;36mGromacsTopFile._processFile\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    129\u001b[0m     append \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (append, line[:line\u001b[38;5;241m.\u001b[39mrfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_processLine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     append \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/openff/lib/python3.9/site-packages/openmm/app/gromacstopfile.py:165\u001b[0m, in \u001b[0;36mGromacsTopFile._processLine\u001b[0;34m(self, line, file)\u001b[0m\n\u001b[1;32m    162\u001b[0m     file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mdir\u001b[39m, name)\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(file):\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# We found the file, so process it.\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_processFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/openff/lib/python3.9/site-packages/openmm/app/gromacstopfile.py:131\u001b[0m, in \u001b[0;36mGromacsTopFile._processFile\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    129\u001b[0m     append \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (append, line[:line\u001b[38;5;241m.\u001b[39mrfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_processLine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     append \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/openff/lib/python3.9/site-packages/openmm/app/gromacstopfile.py:240\u001b[0m, in \u001b[0;36mGromacsTopFile._processLine\u001b[0;34m(self, line, file)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processExclusion(line)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currentCategory \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpairs\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_processPair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currentCategory \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstraints\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processConstraint(line)\n",
      "File \u001b[0;32m~/miniconda3/envs/openff/lib/python3.9/site-packages/openmm/app/gromacstopfile.py:364\u001b[0m, in \u001b[0;36mGromacsTopFile._processPair\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mToo few fields in [ pairs ] line: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mline)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fields[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnsupported function type in [ pairs ] line: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mline)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currentMoleculeType\u001b[38;5;241m.\u001b[39mpairs\u001b[38;5;241m.\u001b[39mappend(fields)\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported function type in [ pairs ] line:      1    11     2 0.833333    -0.125447    -0.033096  3.39966950842e-01  7.62882666667e-02\n"
     ]
    }
   ],
   "source": [
    "yaml_builder.run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63615f1-7531-42fa-a9f7-d7a052597d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
